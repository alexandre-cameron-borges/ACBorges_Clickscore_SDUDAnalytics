# DUDAÂ Clickscore v1

> Le DUDA Clickscore est le MVP d'une Webapp streamlit de Clickscoring rÃ©alisÃ©e pour le DU Sorbonne Data Analytics 2025-2026 par Alexandre Cameron BORGES.
BasÃ© sur 2 modÃ¨les utilisant PyTorch, BERT, Huggingface avec un Fine-tuning multi-tÃ¢che (classification clickbaitness + rÃ©gression linÃ©aire CTR) sur plusieurs dataset d'interactions en ligne (MIND, Webis, Kaggle..)

Contexte: Les investissements publicitaires en ligne sont de plus en plus omniprÃ©sents pour les petites et grandes entreprises, cet outil vise Ã  aider Ã  la prise de dÃ©cision des responsables marketing quant Ã  quelles publicitÃ©s privilÃ©gier afin d'Ã©conomiser en budget A/B test.
L'idÃ©e est Ã©galement de rÃ©cupÃ©rer une part de la connaissance de l'efficacitÃ© publicitaire, connaissance qui est cloisonnÃ©e par les plateformes publicitaires comme Google ou Meta

Google Colab de prÃ©paration: https://colab.research.google.com/drive/1lrgvBJ_1BHrT732r1RnnV1ZBOvZKzZN5?usp=sharing 

VidÃ©o explicative: https://drive.google.com/drive/folders/1pvxEq-HsV99_zG1A3AIUmYXZUuTeT0SN?usp=drive_link 

<p align="center">
  <a href="https://acb-dudaclickscore.streamlit.app/" target="_blank"><img alt="Streamlit app" src="https://img.shields.io/badge/DEMO-online-success?logo=streamlit"></a>
  <img alt="Python" src="https://img.shields.io/badge/Python-3.10+-blue?logo=python">
</p>

---

## Â· 1ï¸âƒ£ âœ¨â€¯Objectif

* **Classer** automatiquement des messages publicitaires en trois niveauxÂ : `Nobait`, `Softbait`, `Clickbait`.
* **PrÃ©dire** le *Clickâ€‘Through Rate* (CTR) attendu dâ€™un texte publicitaire.
* Fournir une **interface simple** permettant aux marketers dâ€™importer un CSV de publicitÃ©s (texteâ€¯+â€¯image) et dâ€™obtenir en quelques secondes des recommandations basÃ©es sur des modÃ¨les BERT fineâ€‘tunÃ©s.

## Â· 2ï¸âƒ£ ğŸš€â€¯DÃ©mo rapide

1. Ouvrez la WebApp hÃ©bergÃ©e â†’ [https://acb-dudaclickscore.streamlit.app/](https://acb-dudaclickscore.streamlit.app/)

2. Choisissez le **cible dÃ©mographique** (Ã¢ge, genre).

3. Importez un CSV comportant deux colonnes, avec jusqu'Ã  10 textes publicitaires Ã  testerÂ :

   | image              | texte                       |
   | ------------------ | --------------------------- |
   | path/to/banner.png | "Free shipping this weekÂ !" |

4. Cliquez sur **PrÃ©dire** et laissez la magie opÃ©rerÂ !

## Â· 3ï¸âƒ£ ğŸ“Šâ€¯Jeux de donnÃ©es

| Domaine               | Source                         | Lien                                                                                                   |
| --------------------- | ------------------------------ | ------------------------------------------------------------------------------------------------------ |
| ClickbaitÂ (EN)        | KaggleÂ Â«â€¯ClickbaitÂ Headlinesâ€¯Â» | [amananandrai/clickbait-dataset](https://www.kaggle.com/datasets/amananandrai/clickbait-dataset)                                                                       |
| AdsÂ clicks            | KaggleÂ Â«â€¯AdÂ ClickÂ Predictionâ€¯Â» | [marius2303/ad-click-prediction-dataset](https://www.kaggle.com/datasets/marius2303/ad-click-prediction-dataset )`                                                               |
| Advertising clicks          | KaggleÂ Â«â€¯AdvertisingÂ CSVâ€¯Â»     | [souvik1618/advertising-dataset](https://www.kaggle.com/datasets/marius2303/ad-click-prediction-dataset)`                                                                       |
| News CTR              | Microsoft **MIND**             | [https://msnews.github.io/](https://msnews.github.io/)                                                 |
| ClickbaitÂ multiâ€‘modal | **WebisÂ ClickbaitÂ 2017**       | [https://webis.de/competitions/clickbait-2017.html](https://zenodo.org/records/5530410) |

Les jeux Kaggle & WEBIS ont Ã©tÃ© nettoyÃ©s, normalisÃ©s (colonnes: texte, age, genre, clickbait o/n) et fusionnÃ©s puis enrichis (imputation dâ€™Ã¢ge, de genre et de *truthMean=probabilitÃ© de clickbait*) afin d'entraÃ®ner le modÃ¨le de classification clickbait, le Dataset MIND a Ã©tÃ© transformÃ© seul pour le modÃ¨le de rÃ©gression linÃ©aire CTR (calcul du CTR Ã  partir du nombre de clics et nombres d'affichages d'un Id publicitaire correspondant Ã  des titres publicitaires) dans le notebook [`data_and_finetuning.ipynb`](data_and_finetuning.ipynb).

## Â· 4ï¸âƒ£ ğŸ§ â€¯ModÃ¨les

Base: BERT est un modÃ¨le de langage lancÃ© fin 2018 : il repose sur un bloc Transformer qui â€œregardeâ€ chaque phrase simultanÃ©ment vers la gauche et vers la droite ; durant son prÃ©-apprentissage, il apprend la grammaire et le sens en devinant des mots cachÃ©s et en testant si deux phrases se suivent ; une fois ce socle acquis, on ne remplace que la petite couche finale pour adapter BERT Ã  presque nâ€™importe quelle tÃ¢che (analyse de sentiments, FAQ, prÃ©diction de clicsâ€¦)

| TÃ¢che           | Architecture                                                         | Dataset dâ€™entraÃ®nement     | MÃ©triquesÂ (val set)      |
| --------------- | -------------------------------------------------------------------- | -------------------------- | ------------------------ |
| **Clickbaitâ€¯Â±** | BERTâ€¯+Â features (Ã¢ge, genre) <br> multiâ€‘taskÂ `CB_F1Â +Â truthMeanÂ Acc` | (62767 lignes * 5 colonnes) Fusion Kaggle &Â Webis      | F1Â â‰ˆÂ 0â€¯.90 (sur 1 ; cela mesure Ã  la fois les bons â€œouiâ€ et les bons â€œnonâ€) / AccÂ â‰ˆâ€¯0â€¯.71 (71 % des titres bien classÃ©s)|
| **CTRâ€¯%**       | BERTÂ regression <br> (sigmoÃ¯de 0â€‘1: pour quâ€™il reste dans 0-100 %)                                 | (10189 lignes * 2 colonnes) MIND (â‰¥â€¯100 impr.) | RMSEÂ â‰ˆÂ 0â€¯.018 (en moyenne le modÃ¨le se trompe de 1,8 points sur 100 dans le pourcentage cliquÃ©)           |

Les poids entraÃ®nÃ©s (< 5 epoch) sont stockÃ©s sur mon compte privÃ© **HuggingÂ Face** et chargÃ©s *Ã  la volÃ©e* via lâ€™API. Le dÃ©pÃ´t Hugging Face: https://huggingface.co/alexandre-cameron-borges

## Â· 5ï¸âƒ£ ğŸ—ï¸â€¯Architecture de lâ€™application

```
app.py (Streamlit)
 â”œâ”€ models/
 â”‚   â””â”€ predict.py  â† lazyâ€‘loading & inference
 â”œâ”€ requirements.txt
 â””â”€ notebooks/ (prÃ©paration & fineâ€‘tuning)
```

1. Lâ€™utilisateur charge son CSV.
2. `predict.py` tÃ©lÃ©charge (la premiÃ¨re fois) puis met en cache les deux modÃ¨les Ã  partir de HuggingÂ Face.
3. Pour chaque texteÂ :

   * Classification probabilitÃ© *clickbait*Â ;
   * CTR prÃ©vu.
4. Les rÃ©sultats sont normalisÃ©s, triÃ©s et affichÃ©s sous forme de tableau + de deux graphiques (scatter & pie chart).

## Â· 6ï¸âƒ£ âš™ï¸â€¯Installation locale

```bash
# 1. Cloner le repo
$ git clone https://github.com/alexandre-cameron-borges/duda_clickscore.git
$ cd duda_clickscore

# 2. CrÃ©er lâ€™environnement
$ python3 -m venv .venv && source .venv/bin/activate

# 3. Installer les dÃ©pendances
$ pip install -r requirements.txt

# 4. DÃ©finir votre token HF (modÃ¨les privÃ©s)
$ export HUGGINGFACE_TOKEN="<votre_token_personnel>"

# 5. Lancer la WebApp
$ streamlit run app.py
```

> **Noteâ€¯:** si la variable `HUGGINGFACE_TOKEN` est absente, lâ€™application sâ€™arrÃªte avec le message dâ€™erreur appropriÃ©. Ajoutezâ€‘la dans **Secrets** lorsque vous dÃ©ployez la WebApp sur *Streamlit Community Cloud*.

## Â· 7ï¸âƒ£ ğŸ—‚ï¸â€¯Organisation du dÃ©pÃ´t

```
â”œâ”€â”€ app.py               # Script Streamlit principal
â”œâ”€â”€ models/
â”‚   â””â”€â”€ predict.py       # Fonctions dâ€™infÃ©rence + chargement des poids
â”œâ”€â”€ requirements.txt     # DÃ©pendances Python
â”œâ”€â”€ *.ipynb / *.py       # Notebooks & scripts de dataâ€‘prep / fineâ€‘tuning
â””â”€â”€ docs/                # SchÃ©mas & ressources (optionnel)
```

## ğŸ™‹â€¯Auteur

 **AlexandreÂ CameronÂ BORGES** â”€ [LinkedIn](https://fr.linkedin.com/in/alexandre-cameron-borges) 

> *â€œIn God We Trust, All the Others We Want Dataâ€*

---

*DerniÃ¨re mise Ã  jourÂ : 18Â maiÂ 2025*

import streamlit as st
import os
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# 0Ô∏è‚É£ Token HF
if "HUGGINGFACE_TOKEN" not in st.secrets:
    st.error("‚ö†Ô∏è Vous devez d√©finir HUGGINGFACE_TOKEN dans vos Secrets Streamlit.")
    st.stop()
os.environ["HUGGINGFACE_TOKEN"] = st.secrets["HUGGINGFACE_TOKEN"]

# 1Ô∏è‚É£ Imports pr√©diction
from models.predict import predict_cb, predict_ctr

# 2Ô∏è‚É£ UI Setup
st.set_page_config(page_title="Alexandre's DUDA Clickscore v1", layout="centered")
st.title("üí° Alexandre's DUDA Clickscore v1")
st.markdown('''Le :rainbow[DUDA Clickscore] est le **MVP d'une Webapp streamlit de Clickscoring r√©alis√©e pour le DU Sorbonne Data Analytics 2025-2026 par Alexandre Cameron BORGES**.  
Bas√© sur 2 mod√®les utilisant PyTorch, BERT, Huggingface avec un Fine-tuning multi-t√¢che (classification clickbait + r√©gression lin√©aire CTR) sur plusieurs dataset (MIND, Webis, Kaggle..)

**Contexte:** Les investissements publicitaires en ligne sont de plus en plus omnipr√©sents pour les petites et grandes entreprises,  
cet outil vise √† aider √† la prise de d√©cision des responsables marketing quant √† quelles publicit√©s privil√©gier afin d'√©conomiser en budget A/B test.  
L'id√©e est √©galement de r√©cup√©rer une part de la connaissance de l'efficacit√© publicitaire, connaissance qui est cloisonn√©e par les plateformes publicitaires''')

# 3Ô∏è‚É£ Constantes & mapping
MEDIAN_AGE = 35.0
MAX_AGE    = 80.0
gender_map = {"Male":0, "Female":1, "Unknown":2}

# 4Ô∏è‚É£ S√©lecteurs
col_age, col_genre = st.columns([0.6, 0.4])
with col_age:
    age = st.slider("üéØ √Çge cible", 18, 99, 30)
with col_genre:
    genre = st.selectbox("üë§ Genre cible", list(gender_map.keys()))

# 5Ô∏è‚É£ Upload CSV
uploaded_file = st.file_uploader("üìÇ Importez votre CSV (colonnes: image, texte)", type="csv")
if not uploaded_file:
    st.info("Veuillez importer un fichier CSV.")
    st.stop()
df = pd.read_csv(uploaded_file)
if not {"image","texte"}.issubset(df.columns):
    st.error("Les colonnes requises sont : image, texte")
    st.stop()
df = df.head(10)

# 6Ô∏è‚É£ Pr√©diction + barre
if st.button("üöÄ Pr√©dire"):
    age_norm  = (age - MEDIAN_AGE) / (MAX_AGE - MEDIAN_AGE)
    gender_id = gender_map[genre]
    total     = len(df)
    bar       = st.progress(0, text="Chargement‚Ä¶")

    # 1) Collecte des proba clickbait et CTR
    pcbs, textes, pctrs = [], [], []
    for i, row in enumerate(df.itertuples(), start=1):
        texte = row.texte.strip()
        p_cb_orig  = predict_cb(texte, age_norm, gender_id)
        p_ctr_orig = predict_ctr(texte)

        # Att√©nuation graduelle pour textes trop courts
        if len(texte) < 7:
            p_cb  = p_cb_orig * 0.2
            p_ctr = p_ctr_orig * 0.3
        else:
            p_cb, p_ctr = p_cb_orig, p_ctr_orig

        pcbs.append(p_cb)
        textes.append(texte)
        pctrs.append(p_ctr)
        bar.progress(i/total, text=f"{i}/{total}")
    bar.empty()

    # 2) Seuils dynamiques
    Q1, Q2 = np.percentile(pcbs, [33, 66])

    # 3) Construction r√©sultats
    results = []
    for texte, p_cb, p_ctr in zip(textes, pcbs, pctrs):
        if   p_cb < Q1:
            label = "üî¥ Nobait"
        elif p_cb < Q2:
            label = "üü† Softbait"
        else:
            label = "üü¢ Clickbait"
        results.append({
            "Texte":          texte,
            "Classification": label,
            "CTR pr√©dit":     f"{p_ctr:.2f}%"
        })

    st.success("‚úÖ Pr√©diction termin√©e !")
    st.balloons()

    # 7Ô∏è‚É£ Affichage
    df_res = pd.DataFrame(results)
    df_res["CTR_num"] = df_res["CTR pr√©dit"].str.rstrip("%").astype(float)
    df_res = df_res.sort_values("CTR_num", ascending=False)

    st.subheader("üîΩ Tableau tri√© par CTR pr√©dit")
    st.table(df_res[["Texte","Classification","CTR pr√©dit"]])

    # Graphiques
    color_map = {"üî¥ Nobait":"red","üü† Softbait":"orange","üü¢ Clickbait":"green"}
    encode    = {"üî¥ Nobait":0,"üü† Softbait":1,"üü¢ Clickbait":2}
    x = df_res["Classification"].map(encode) + np.random.normal(0,0.05,len(df_res))

    fig, ax = plt.subplots(figsize=(5,4))
    ax.scatter(x, df_res["CTR_num"], c=df_res["Classification"].map(color_map), s=300, alpha=0.7, edgecolors="w")
    ax.set_xticks([0,1,2])
    ax.set_xticklabels(["Nobait","Softbait","Clickbait"])
    ax.set_ylabel("CTR pr√©dit (%)")
    ax.set_title("CTR vs Classification")
    plt.tight_layout()

    counts = df_res["Classification"].value_counts().reindex(color_map.keys(), fill_value=0)
    fig2, ax2 = plt.subplots(figsize=(5,4))
    ax2.pie(counts, labels=counts.index, autopct="%1.1f%%", startangle=90,
            colors=[color_map[l] for l in counts.index])
    ax2.set_title("R√©partition des classes")
    ax2.axis("equal")

    c1, c2 = st.columns([0.5, 0.5])
    with c1: st.pyplot(fig, use_container_width=True)
    with c2: st.pyplot(fig2, use_container_width=True)
